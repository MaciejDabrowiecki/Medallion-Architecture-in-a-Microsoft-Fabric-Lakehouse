{"cells":[{"cell_type":"code","source":["from pyspark.sql.functions import (\n","    col, year, month, dayofmonth, weekofyear,\n","    date_format, quarter, dayofweek, when, lit\n",")\n","\n","# Pull data from silver.calendar table to DataFrame\n","\n","df_calendar = spark.table(\"silver.calendar\")\n","\n","#Perform transformations\n","\n","df_dim_date = (\n","    df_calendar\n","    .select(col(\"Date\"))\n","    .dropDuplicates()\n","    .withColumn(\"DateKey\", date_format(col(\"Date\"), \"yyyyMMdd\").cast(\"int\"))\n","    .withColumn(\"Day\", dayofmonth(col(\"Date\")))\n","    .withColumn(\"DayName\", date_format(col(\"Date\"), \"EEEE\"))\n","    .withColumn(\"DayOfWeek\", dayofweek(col(\"Date\")))\n","    .withColumn(\"WeekOfYear\", weekofyear(col(\"Date\")))\n","    .withColumn(\"Month\", month(col(\"Date\")))\n","    .withColumn(\"MonthName\", date_format(col(\"Date\"), \"MMMM\"))\n","    .withColumn(\"Quarter\", quarter(col(\"Date\")))\n","    .withColumn(\"Year\", year(col(\"Date\")))\n","    .withColumn(\n","        \"IsWeekend\",\n","        when(dayofweek(col(\"Date\")).isin(1, 7), lit(True)).otherwise(lit(False))\n","    )\n",")\n","\n","# Select and reorder columns\n","\n","df_dim_date = df_dim_date.select(\n","    \"DateKey\",\n","    \"Date\",\n","    \"Day\",\n","    \"DayName\",\n","    \"DayOfWeek\",\n","    \"WeekOfYear\",\n","    \"Month\",\n","    \"MonthName\",\n","    \"Quarter\",\n","    \"Year\",\n","    \"IsWeekend\"\n",")\n","\n","# Insert data into gold.dim_date table\n","\n","(\n","    df_dim_date\n","    .write\n","    .format(\"delta\")\n","    .mode(\"overwrite\")\n","    .option(\"overwriteSchema\", \"true\")\n","    .saveAsTable(\"gold.dim_date\")\n",")\n","\n","#"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"23709a00-0143-4b2e-88af-9f3359c142d9","normalized_state":"finished","queued_time":"2026-01-08T10:55:51.648506Z","session_start_time":"2026-01-08T10:55:51.6500709Z","execution_start_time":"2026-01-08T10:56:01.6628812Z","execution_finish_time":"2026-01-08T10:56:22.295426Z","parent_msg_id":"e609ab75-323d-4b9e-8e23-ac0ad6f1d076"},"text/plain":"StatementMeta(, 23709a00-0143-4b2e-88af-9f3359c142d9, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"b9a52c10-397e-4bfd-9392-138ce78e628b"},{"cell_type":"code","source":["from pyspark.sql.functions import *\n","\n","# Pull data from silver.products Delta Table to DataFrame\n","\n","df_products_silver = spark.table(\"silver.products\")\n","\n","#Perform transformations\n","\n","df_dim_product = (\n","    df_products_silver\n","    .select(\n","        col(\"ProductKey\"),\n","        trim(col(\"ProductSKU\")).alias(\"ProductSKU\"),\n","        initcap(trim(col(\"ProductName\"))).alias(\"ProductName\"),\n","        initcap(trim(col(\"ModelName\"))).alias(\"ModelName\"),\n","        initcap(trim(col(\"CategoryName\"))).alias(\"CategoryName\"),\n","        initcap(trim(col(\"SubcategoryName\"))).alias(\"SubcategoryName\")\n","    )\n",")\n","\n","# IMPORTANT! AdventureWorks dataset does not have prices provided for the products.\n","# We will populate synthetic prices based on products categories and subcategories for analytical purposes.\n","# Columns added will be a ListPrice and StandardCost that will be based on temporary columns CategoryBasePrice and SubcategoryMultiplier.\n","\n","df_dim_product = (df_dim_product\n","    .withColumn(\n","        \"CategoryBasePrice\",\n","        when(col(\"CategoryName\") == \"Bikes\", 800)\n","        .when(col(\"CategoryName\") == \"Components\", 150)\n","        .when(col(\"CategoryName\") == \"Clothing\", 40)\n","        .when(col(\"CategoryName\") == \"Accessories\", 25)\n","        .otherwise(50)\n","    )\n","    .withColumn(\n","        \"SubcategoryMultiplier\",\n","        when(col(\"SubcategoryName\").like(\"%Road%\"), 1.3)\n","        .when(col(\"SubcategoryName\").like(\"%Mountain%\"), 1.2)\n","        .when(col(\"SubcategoryName\").like(\"%Helmet%\"), 1.1)\n","        .when(col(\"SubcategoryName\").like(\"%Sock%\"), 0.8)\n","        .otherwise(1.0)\n","    )\n","    .withColumn(\n","        \"ListPrice\",\n","        round(\n","            col(\"CategoryBasePrice\") * col(\"SubcategoryMultiplier\")\n","            + (col(\"ProductKey\") % 10) * 3,\n","            2)\n","    )\n","    .withColumn(\"StandardCost\", round(col(\"ListPrice\") * 0.6, 2))\n",")\n","\n","\n","# Select and reorder columns\n","\n","df_dim_product = df_dim_product.select(\n","    \"ProductKey\",\n","    \"ProductSKU\",\n","    \"ProductName\",\n","    \"ModelName\",\n","    \"CategoryName\",\n","    \"SubcategoryName\",\n","    \"ListPrice\",\n","    \"StandardCost\"\n",")\n","\n","\n","# Write data to gold.dim_product delta table\n","\n","(\n","    df_dim_product\n","    .write\n","    .format(\"delta\")\n","    .mode(\"overwrite\")\n","    .option(\"overwriteSchema\", \"true\")\n","    .saveAsTable(\"gold.dim_product\")\n",")\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"f35d49f5-5edc-41ff-b672-f98e30abb992","normalized_state":"finished","queued_time":"2026-01-09T13:59:48.3353547Z","session_start_time":null,"execution_start_time":"2026-01-09T13:59:48.3371569Z","execution_finish_time":"2026-01-09T14:00:13.1645906Z","parent_msg_id":"228cbef2-06b4-49d2-9776-eb3fe2b65e28"},"text/plain":"StatementMeta(, f35d49f5-5edc-41ff-b672-f98e30abb992, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"ff992f4d-ee20-4e3d-944c-cd33ec8fc399"},{"cell_type":"code","source":["from pyspark.sql.functions import (\n","    col, concat_ws, year, current_date, lower, split\n",")\n","\n","# Pull data from silver.sales Delta Table to DataFrame\n","\n","df_customers_silver = spark.table(\"silver.customers\")\n","\n","df_dim_customer = (\n","    df_customers_silver\n","    .select(\n","        col(\"CustomerKey\"),\n","        col(\"FirstName\"),\n","        col(\"LastName\"),\n","        col(\"Gender\"),\n","        col(\"MaritalStatus\"),\n","        col(\"BirthDate\"),\n","        col(\"AnnualIncome\"),\n","        col(\"EducationLevel\"),\n","        col(\"Occupation\"),\n","        col(\"HomeOwner\"),\n","        col(\"Email\")\n","    )\n","# Add new columns with full name, age and email domain\n","    .withColumn(\n","        \"FullName\", \n","        concat_ws(\" \", col(\"FirstName\"), col(\"LastName\"))\n","    )\n","    .withColumn(\n","        \"Age\",\n","        year(current_date()) - year(col(\"BirthDate\"))\n","    )\n","    .withColumn(\n","        \"EmailDomain\",\n","        lower(split(col(\"Email\"), \"@\").getItem(1))\n","    )\n",")\n","\n","# Select and reorder columns\n","\n","df_dim_customer = df_dim_customer.select(\n","    \"CustomerKey\",\n","    \"FullName\",\n","    \"FirstName\",\n","    \"LastName\",\n","    \"Gender\",\n","    \"MaritalStatus\",\n","    \"Age\",\n","    \"AnnualIncome\",\n","    \"EducationLevel\",\n","    \"Occupation\",\n","    \"HomeOwner\",\n","    \"Email\",\n","    \"EmailDomain\"\n",")\n","\n","# Write data to gold.dim_customer delta table\n","\n","(\n","    df_dim_customer\n","    .write\n","    .format(\"delta\")\n","    .mode(\"overwrite\")\n","    .option(\"overwriteSchema\", \"true\")\n","    .saveAsTable(\"gold.dim_customer\")\n",")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"8b4f5cf9-ab4b-4353-bb1a-5abdd204f8c0","normalized_state":"finished","queued_time":"2026-01-08T14:59:13.7179484Z","session_start_time":null,"execution_start_time":"2026-01-08T14:59:13.7198952Z","execution_finish_time":"2026-01-08T14:59:55.6104204Z","parent_msg_id":"7d8aed59-b3e5-4f72-b953-3768817429a2"},"text/plain":"StatementMeta(, 8b4f5cf9-ab4b-4353-bb1a-5abdd204f8c0, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c14089b5-3423-4ba6-8d33-76dd374c71de"},{"cell_type":"code","source":["from pyspark.sql.functions import col, initcap, trim\n","\n","# Pull data from silver.territories delta table to DataFrame\n","\n","df_territories_silver = spark.table(\"silver.territories\")\n","\n","# Select and transform columns\n","\n","df_dim_territory = (\n","    df_territories_silver\n","    .select(\n","        col(\"TerritoryKey\"),\n","        initcap(trim(col(\"Region\"))),\n","        initcap(trim(col(\"Country\"))),\n","        initcap(trim(col(\"Continent\")))\n","    )\n",")\n","# Write data to gold.dim_territory delta table\n","\n","(\n","    df_dim_territory\n","    .write\n","    .format(\"delta\")\n","    .mode(\"overwrite\")\n","    .option(\"overwriteSchema\", \"true\")\n","    .saveAsTable(\"gold.dim_territory\")\n",")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"ebddee9f-a9a0-41b3-aea9-7578e8863794","normalized_state":"finished","queued_time":"2026-01-08T15:07:55.4735997Z","session_start_time":"2026-01-08T15:07:55.4751111Z","execution_start_time":"2026-01-08T15:08:06.1368357Z","execution_finish_time":"2026-01-08T15:08:29.6221126Z","parent_msg_id":"7b0df60f-a315-4e51-96a4-6b65aa2296d4"},"text/plain":"StatementMeta(, ebddee9f-a9a0-41b3-aea9-7578e8863794, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"acf38384-a380-43b4-a538-db167d1d6ed7"},{"cell_type":"code","source":["from pyspark.sql.functions import col, round\n","from pyspark.sql.types import DecimalType\n","\n","# Pull data from gold dimensions and silver sales delta tables\n","\n","df_sales = spark.table(\"silver.sales\")\n","df_dim_date = spark.table(\"gold.dim_date\")\n","df_dim_customer = spark.table(\"gold.dim_customer\")\n","df_dim_product = spark.table(\"gold.dim_product\")\n","df_dim_territory = spark.table(\"gold.dim_territory\")\n","\n","#Join tables on keys to enforce star schema and ensure data integrity\n","\n","df_sales_enriched = (\n","    df_sales\n","    .join(\n","        df_dim_date,\n","        df_sales.OrderDate == df_dim_date.Date,\n","        \"left\"\n","    )\n","    .join(\n","        df_dim_customer,\n","        df_sales.CustomerID == df_dim_customer.CustomerKey,\n","        \"left\"\n","    )\n","    .join(\n","        df_dim_product,\n","        df_sales.ProductID == df_dim_product.ProductKey,\n","        \"left\"\n","    )\n","    .join(\n","        df_dim_territory,\n","        df_sales.TerritoryID == df_dim_territory.TerritoryKey,\n","        \"left\"\n","    )\n",")\n","\n","\n","# IMPORTANT! AdventureWorks dataset does not have prices provided for the products.\n","# We already populated synthetic prices for product dimension.\n","# Now we will use those new columns to create fact_sales price columns for analytical purposes.\n","# Columns added will be a UnitPrice based on dim_product.ListPrice and SalesAmount - UnitPrice mutiplied by OrderQuantity.\n","\n","df_sales_enriched = (df_sales_enriched\n","    .withColumn(\"UnitPrice\", col(\"ListPrice\").cast(DecimalType(10, 2))\n","    )\n","    .withColumn(\"SalesAmount\", round(col(\"Quantity\") * col(\"UnitPrice\"), 2).cast(DecimalType(12, 2)))\n",")\n","\n","# Reorder, rename and filter columns\n","\n","df_fact_sales = df_sales_enriched.select(\n","    col(\"SalesOrderNumber\"),\n","    col(\"SalesOrderLineNumber\"),\n","    col(\"DateKey\").alias(\"OrderDateKey\"),\n","    col(\"CustomerID\").alias(\"CustomerKey\"),\n","    col(\"ProductID\").alias(\"ProductKey\"),\n","    col(\"TerritoryID\").alias(\"TerritoryKey\"),\n","    col(\"Quantity\"),\n","    col(\"UnitPrice\"),\n","    col(\"SalesAmount\")\n",")\n","\n","# Check for missing dimension keys\n","df_fact_sales.filter(\n","    col(\"OrderDateKey\").isNull()\n","    | col(\"CustomerKey\").isNull()\n","    | col(\"ProductKey\").isNull()\n","    | col(\"TerritoryKey\").isNull()\n",").count()\n","\n","#Write DataFrame to gold.fact_sales Delta Table\n","\n","df_fact_sales.write \\\n","    .mode(\"overwrite\") \\\n","    .format(\"delta\") \\\n","    .saveAsTable(\"gold.fact_sales\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"819ab9f3-3560-4d1d-bf2b-4c73f8cf1766","normalized_state":"finished","queued_time":"2026-01-09T15:23:24.655035Z","session_start_time":null,"execution_start_time":"2026-01-09T15:23:24.6568998Z","execution_finish_time":"2026-01-09T15:23:55.8056256Z","parent_msg_id":"2ac5a0c0-5351-43ee-9d94-6e55acd5e6b0"},"text/plain":"StatementMeta(, 819ab9f3-3560-4d1d-bf2b-4c73f8cf1766, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"5e94b0e7-f3a5-4859-99ce-1599809dd05e"},{"cell_type":"code","source":["from pyspark.sql.functions import col\n","from pyspark.sql.types import DecimalType, IntegerType\n","\n","# Read data from gold dimensions and silver returns delta tables\n","\n","df_returns = spark.table(\"silver.returns\")\n","df_dim_date = spark.table(\"gold.dim_date\")\n","df_dim_product = spark.table(\"gold.dim_product\")\n","df_dim_territory = spark.table(\"gold.dim_territory\")\n","\n","# Join tables on keys to enforce star schema and ensure data integrity\n","\n","df_returns_enriched = (\n","    df_returns.alias(\"r\")\n","    .join(\n","        df_dim_date.alias(\"d\"),\n","        col(\"r.ReturnDate\") == col(\"d.Date\"),\n","        \"left\"\n","    )\n","    .join(\n","        df_dim_product.alias(\"p\"),\n","        col(\"r.ProductKey\") == col(\"p.ProductKey\"),\n","        \"left\"\n","    )\n","    .join(\n","        df_dim_territory.alias(\"t\"),\n","        col(\"r.TerritoryKey\") == col(\"t.TerritoryKey\"),\n","        \"left\"\n","    )\n",")\n","\n","# Perform final select, type casting and adding price columns\n","\n","df_fact_returns = (\n","    df_returns_enriched\n","    .select(\n","        col(\"d.DateKey\").alias(\"ReturnDateKey\"),\n","        col(\"p.ProductKey\").cast(IntegerType()).alias(\"ProductKey\"),\n","        col(\"t.TerritoryKey\").cast(IntegerType()).alias(\"TerritoryKey\"),\n","        col(\"r.ReturnQuantity\").cast(IntegerType()).alias(\"ReturnQuantity\"),\n","        col(\"p.ListPrice\").cast(DecimalType(10, 2)).alias(\"UnitPrice\"),\n","        (col(\"r.ReturnQuantity\") * col(\"p.ListPrice\"))\n","            .cast(DecimalType(12, 2))\n","            .alias(\"ReturnAmount\")\n","    )\n",")\n","\n","# Write data to gold fact_returns delta table\n","\n","df_fact_returns.write \\\n","    .format(\"delta\") \\\n","    .mode(\"append\") \\\n","    .saveAsTable(\"gold.fact_returns\")\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"1d27190f-db0f-4fa9-9b7e-63575f24c24b","normalized_state":"finished","queued_time":"2026-01-09T16:23:22.1642303Z","session_start_time":"2026-01-09T16:23:22.1658605Z","execution_start_time":"2026-01-09T16:23:32.9501152Z","execution_finish_time":"2026-01-09T16:24:05.1246849Z","parent_msg_id":"62e64c88-e077-4cf1-871d-6f8506ea7843"},"text/plain":"StatementMeta(, 1d27190f-db0f-4fa9-9b7e-63575f24c24b, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"7b17237d-e947-46ec-a352-e32311a07382"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"cca0b484-3595-4555-858a-b915fa4c6989","known_lakehouses":[{"id":"cca0b484-3595-4555-858a-b915fa4c6989"}],"default_lakehouse_name":"lh_sales","default_lakehouse_workspace_id":"dad49cf8-6333-4c01-b8ec-6530251e8652"}}},"nbformat":4,"nbformat_minor":5}